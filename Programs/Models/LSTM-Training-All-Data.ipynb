{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, roc_curve, auc, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./10ms_50rows/\"\n",
    "# x_S1_scaled_XYZ_10ms_50lb\n",
    "S1_x = np.load(data_path + \"x_S1_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "S1_y = np.load(data_path + \"y_S1_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "\n",
    "S2_x = np.load(data_path + \"x_S2_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "S2_y = np.load(data_path + \"y_S2_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "\n",
    "S3_x = np.load(data_path + \"x_S3_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "S3_y = np.load(data_path + \"y_S3_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "\n",
    "C1_x = np.load(data_path + \"x_C1_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "C1_y = np.load(data_path + \"y_C1_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "\n",
    "C2_x = np.load(data_path + \"x_C2_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "C2_y = np.load(data_path + \"y_C2_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "\n",
    "C3_x = np.load(data_path + \"x_C3_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n",
    "C3_y = np.load(data_path + \"y_C3_scaled_XYZ_10ms_50lb.npy\").astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65048856, -0.29491472,  0.04537556],\n",
       "       [ 0.6443313 , -0.30964693,  0.04340368],\n",
       "       [ 0.6350953 , -0.3219238 ,  0.06706619],\n",
       "       [ 0.6073874 , -0.30801004,  0.11439119],\n",
       "       [ 0.58429754, -0.34565908,  0.12720837],\n",
       "       [ 0.58429754, -0.33338222,  0.12227868],\n",
       "       [ 0.5612076 , -0.34565908,  0.1410115 ],\n",
       "       [ 0.54581434, -0.35548055,  0.15284275],\n",
       "       [ 0.50579184, -0.3702128 ,  0.17946307],\n",
       "       [ 0.50117385, -0.37512353,  0.19819587],\n",
       "       [ 0.50579184, -0.39885882,  0.22185838],\n",
       "       [ 0.46115136, -0.39558497,  0.24453494],\n",
       "       [ 0.43190417, -0.38085273,  0.275099  ],\n",
       "       [ 0.4288255 , -0.37348664,  0.29876152],\n",
       "       [ 0.37802774, -0.36612052,  0.33326933],\n",
       "       [ 0.3764884 , -0.36857587,  0.33622715],\n",
       "       [ 0.36417377, -0.34811443,  0.3401709 ],\n",
       "       [ 0.31029734, -0.33583757,  0.3480584 ],\n",
       "       [ 0.3472412 , -0.3374745 ,  0.36087558],\n",
       "       [ 0.32107264, -0.3292899 ,  0.35988966],\n",
       "       [ 0.23179168, -0.31210232,  0.38453808],\n",
       "       [ 0.22101639, -0.29491472,  0.37270683],\n",
       "       [ 0.2040838 , -0.26545024,  0.34510058],\n",
       "       [ 0.13943207, -0.2376227 ,  0.29876152],\n",
       "       [ 0.05630843, -0.19260754,  0.29777557],\n",
       "       [-0.04528714, -0.12467556,  0.27904275],\n",
       "       [-0.12995012, -0.06902046,  0.24946463],\n",
       "       [-0.27002886,  0.0144622 ,  0.24749276],\n",
       "       [-0.37470308,  0.11758784,  0.2484787 ],\n",
       "       [-0.43473682,  0.22562422,  0.23368964],\n",
       "       [-0.5317144 ,  0.32711294,  0.18537869],\n",
       "       [-0.65486056,  0.43351242,  0.14396931],\n",
       "       [-0.8826809 ,  0.5620102 ,  0.117349  ],\n",
       "       [-1.0920293 ,  0.7183356 ,  0.10058806],\n",
       "       [-1.2998384 ,  0.8468334 ,  0.08382712],\n",
       "       [-1.561524  ,  0.99824804,  0.07495368],\n",
       "       [-1.8663107 ,  1.193041  ,  0.08777087],\n",
       "       [-2.1957266 ,  1.441852  ,  0.12819432],\n",
       "       [-2.913053  ,  1.8330747 ,  0.13016619],\n",
       "       [-3.8720536 ,  2.3838966 ,  0.1597443 ],\n",
       "       [-4.19993   ,  2.825045  ,  0.05227712],\n",
       "       [-4.3292336 ,  3.2522798 ,  0.05819274],\n",
       "       [-4.9080205 ,  4.300724  ,  0.45453966],\n",
       "       [-5.061953  ,  4.5953684 ,  0.61031777],\n",
       "       [-5.272841  ,  4.8908315 ,  0.73355997],\n",
       "       [-5.580706  ,  5.561148  ,  1.1693444 ],\n",
       "       [-5.740796  ,  6.321495  ,  1.5370991 ],\n",
       "       [-5.4313917 ,  7.0589256 ,  1.8733039 ],\n",
       "       [-5.346729  ,  7.7889895 ,  3.2023478 ],\n",
       "       [-5.132762  ,  8.492863  ,  3.6046102 ]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65048856\n",
      "[0.65048856]\n",
      "0.6443313\n",
      "[0.65048856, 0.6443313]\n",
      "0.6350953\n",
      "[0.65048856, 0.6443313, 0.6350953]\n",
      "0.6073874\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874]\n",
      "0.58429754\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754]\n",
      "0.58429754\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754]\n",
      "0.5612076\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076]\n",
      "0.54581434\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434]\n",
      "0.50579184\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184]\n",
      "0.50117385\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385]\n",
      "0.50579184\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184]\n",
      "0.46115136\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136]\n",
      "0.43190417\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417]\n",
      "0.4288255\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255]\n",
      "0.37802774\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774]\n",
      "0.3764884\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884]\n",
      "0.36417377\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377]\n",
      "0.31029734\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734]\n",
      "0.3472412\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412]\n",
      "0.32107264\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264]\n",
      "0.23179168\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168]\n",
      "0.22101639\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639]\n",
      "0.2040838\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838]\n",
      "0.13943207\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207]\n",
      "0.056308426\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426]\n",
      "-0.045287143\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143]\n",
      "-0.12995012\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012]\n",
      "-0.27002886\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886]\n",
      "-0.37470308\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308]\n",
      "-0.43473682\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682]\n",
      "-0.5317144\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144]\n",
      "-0.65486056\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056]\n",
      "-0.8826809\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809]\n",
      "-1.0920293\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293]\n",
      "-1.2998384\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384]\n",
      "-1.561524\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524]\n",
      "-1.8663107\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107]\n",
      "-2.1957266\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266]\n",
      "-2.913053\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053]\n",
      "-3.8720536\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536]\n",
      "-4.19993\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993]\n",
      "-4.3292336\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993, -4.3292336]\n",
      "-4.9080205\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993, -4.3292336, -4.9080205]\n",
      "-5.061953\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993, -4.3292336, -4.9080205, -5.061953]\n",
      "-5.272841\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993, -4.3292336, -4.9080205, -5.061953, -5.272841]\n",
      "-5.580706\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993, -4.3292336, -4.9080205, -5.061953, -5.272841, -5.580706]\n",
      "-5.740796\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993, -4.3292336, -4.9080205, -5.061953, -5.272841, -5.580706, -5.740796]\n",
      "-5.4313917\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993, -4.3292336, -4.9080205, -5.061953, -5.272841, -5.580706, -5.740796, -5.4313917]\n",
      "-5.346729\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993, -4.3292336, -4.9080205, -5.061953, -5.272841, -5.580706, -5.740796, -5.4313917, -5.346729]\n",
      "-5.132762\n",
      "[0.65048856, 0.6443313, 0.6350953, 0.6073874, 0.58429754, 0.58429754, 0.5612076, 0.54581434, 0.50579184, 0.50117385, 0.50579184, 0.46115136, 0.43190417, 0.4288255, 0.37802774, 0.3764884, 0.36417377, 0.31029734, 0.3472412, 0.32107264, 0.23179168, 0.22101639, 0.2040838, 0.13943207, 0.056308426, -0.045287143, -0.12995012, -0.27002886, -0.37470308, -0.43473682, -0.5317144, -0.65486056, -0.8826809, -1.0920293, -1.2998384, -1.561524, -1.8663107, -2.1957266, -2.913053, -3.8720536, -4.19993, -4.3292336, -4.9080205, -5.061953, -5.272841, -5.580706, -5.740796, -5.4313917, -5.346729, -5.132762]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "for i in range(len(S1_x[0])):\n",
    "#     print(S1_x[0][i][0])\n",
    "    x.append(S1_x[0][i][0])\n",
    "#     print(x)\n",
    "    y.append(S1_x[0][i][1])\n",
    "    z.append(S1_x[0][i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.65048856,\n",
       " 0.6443313,\n",
       " 0.6350953,\n",
       " 0.6073874,\n",
       " 0.58429754,\n",
       " 0.58429754,\n",
       " 0.5612076,\n",
       " 0.54581434,\n",
       " 0.50579184,\n",
       " 0.50117385,\n",
       " 0.50579184,\n",
       " 0.46115136,\n",
       " 0.43190417,\n",
       " 0.4288255,\n",
       " 0.37802774,\n",
       " 0.3764884,\n",
       " 0.36417377,\n",
       " 0.31029734,\n",
       " 0.3472412,\n",
       " 0.32107264,\n",
       " 0.23179168,\n",
       " 0.22101639,\n",
       " 0.2040838,\n",
       " 0.13943207,\n",
       " 0.056308426,\n",
       " -0.045287143,\n",
       " -0.12995012,\n",
       " -0.27002886,\n",
       " -0.37470308,\n",
       " -0.43473682,\n",
       " -0.5317144,\n",
       " -0.65486056,\n",
       " -0.8826809,\n",
       " -1.0920293,\n",
       " -1.2998384,\n",
       " -1.561524,\n",
       " -1.8663107,\n",
       " -2.1957266,\n",
       " -2.913053,\n",
       " -3.8720536,\n",
       " -4.19993,\n",
       " -4.3292336,\n",
       " -4.9080205,\n",
       " -5.061953,\n",
       " -5.272841,\n",
       " -5.580706,\n",
       " -5.740796,\n",
       " -5.4313917,\n",
       " -5.346729,\n",
       " -5.132762]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = np.load('trail.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "l1 = plt.plot(x,label = 'x')\n",
    "l2 = plt.plot(y,label = 'y')\n",
    "l3 = plt.plot(z,label = 'z')\n",
    "l4 = plt.plot(mag,label = 'mag')\n",
    "plt.legend(handles=[l1[0], l2[0],l3[0],l4[0]])\n",
    "# plt.legend((x, y, z), ('label1', 'label2', 'label3'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [S1_x, S2_x, S3_x, C1_x, C2_x]\n",
    "Y_train = [S1_y, S2_y, S3_y, C1_y, C2_y]\n",
    "\n",
    "X_train = np.vstack(X_train)\n",
    "Y_train = np.vstack(Y_train)\n",
    "\n",
    "X_test = C3_x\n",
    "Y_test = C3_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Train and Test LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lstm_simple(X_train, Y_train, X_test, Y_test, time_steps, n_features, params):\n",
    "  # Build the Model\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(params['HL_1'], activation=tf.nn.relu, input_shape=(time_steps, n_features)))\n",
    "  model.add(Dropout(params['drop1']))\n",
    "  model.add(BatchNormalization())\n",
    "#   model.add(Dense(10, activation = tf.nn.relu))\n",
    "  model.add(Dense(1, activation = tf.nn.sigmoid))\n",
    "    \n",
    "#   opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "  callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = params['patience'], verbose=1)\n",
    "  model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = 'nadam', metrics=['accuracy'])\n",
    "\n",
    "  # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)\n",
    "  \n",
    "  # Implement class weights\n",
    "  cw = {\n",
    "      0: params['w0'],\n",
    "      1: params['w1']\n",
    "  }\n",
    "  model.summary()\n",
    "  # Train the model\n",
    "  history = model.fit(X_train, Y_train, epochs = params['epochs'], batch_size = params['batch'], class_weight=cw, callbacks=[callback])\n",
    "\n",
    "  # Predict on data\n",
    "  Y_pred = model.predict(X_test)\n",
    "  Y_pred = np.round(Y_pred, 0)\n",
    "  np.where(Y_pred == 1)\n",
    "  cm = confusion_matrix(Y_test, Y_pred)\n",
    "  print(\"CONFUSION MATRIX\")\n",
    "  print(cm)\n",
    "  print(\"CLASSIFICATION REPORT\")\n",
    "  print(classification_report(Y_test, Y_pred, target_names=[\"non_fall\", \"fall\"]))\n",
    "    \n",
    "  return history, cm, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lstm_cplx(X_train, Y_train, X_test, Y_test, time_steps, n_features, params):\n",
    "  # Build the Model\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(params['HL_1'], activation=tf.nn.relu, input_shape=(time_steps, n_features), return_sequences=True))\n",
    "  model.add(Dropout(params['drop1']))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(LSTM(params['HL_2'], activation=tf.nn.relu))\n",
    "  model.add(Dropout(params['drop2']))\n",
    "  model.add(BatchNormalization())\n",
    "#   model.add(Dense(10, activation = tf.nn.relu))\n",
    "  model.add(Dense(1, activation = tf.nn.sigmoid))\n",
    "    \n",
    "  opt = keras.optimizers.Nadam(learning_rate=params['lr'])\n",
    "  callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = params['patience'], verbose=1)\n",
    "  model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = opt, metrics=['accuracy'])\n",
    "\n",
    "  # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)\n",
    "  \n",
    "  # Implement class weights\n",
    "  cw = {\n",
    "      0: params['w0'],\n",
    "      1: params['w1']\n",
    "  }\n",
    "  model.summary()\n",
    "  # Train the model\n",
    "  history = model.fit(X_train, Y_train, epochs = params['epochs'], batch_size = params['batch'], class_weight=cw, callbacks=[callback], verbose=0)\n",
    "\n",
    "  # Predict on data\n",
    "  Y_pred = model.predict(X_test)\n",
    "  Y_pred = np.round(Y_pred, 0)\n",
    "  np.where(Y_pred == 1)\n",
    "  cm = confusion_matrix(Y_test, Y_pred)\n",
    "  print(\"CONFUSION MATRIX\")\n",
    "  print(cm)\n",
    "  print(\"CLASSIFICATION REPORT\")\n",
    "  print(classification_report(Y_test, Y_pred, target_names=[\"non_fall\", \"fall\"]))\n",
    "    \n",
    "  return history, cm, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 50, 15)            1140      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50, 15)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 50, 15)            60        \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 5)                 420       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 1,646\n",
      "Trainable params: 1,606\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "CONFUSION MATRIX\n",
      "[[33034  3735]\n",
      " [   18    13]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.90      0.95     36769\n",
      "        fall       0.00      0.42      0.01        31\n",
      "\n",
      "    accuracy                           0.90     36800\n",
      "   macro avg       0.50      0.66      0.48     36800\n",
      "weighted avg       1.00      0.90      0.95     36800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = { # With Feature Scaling\n",
    "    'drop1' : 0.2,\n",
    "    'drop2': 0.2,\n",
    "    'w1' : 750.,\n",
    "    'w0' : 1.,\n",
    "    'batch' : 7500,\n",
    "    'epochs' : 5,\n",
    "    'patience' : 5,\n",
    "    'HL_1' : 15,\n",
    "    'HL_2' : 5,\n",
    "    'lr': 0.001,\n",
    "}\n",
    "\n",
    "\n",
    "history, cm, model = eval_lstm_cplx(X_train, Y_train, X_test, Y_test, 50, 3, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.65048856, -0.29491472,  0.04537556],\n",
       "        [ 0.6443313 , -0.30964693,  0.04340368],\n",
       "        [ 0.6350953 , -0.3219238 ,  0.06706619],\n",
       "        ...,\n",
       "        [-5.4313917 ,  7.0589256 ,  1.8733039 ],\n",
       "        [-5.346729  ,  7.7889895 ,  3.2023478 ],\n",
       "        [-5.132762  ,  8.492863  ,  3.6046102 ]],\n",
       "\n",
       "       [[ 1.1677023 ,  0.10285561,  0.03748805],\n",
       "        [ 1.1738597 ,  0.09548949,  0.02467087],\n",
       "        [ 1.1461518 ,  0.09385257,  0.01579743],\n",
       "        ...,\n",
       "        [-3.5133903 ,  4.6092825 ,  3.938843  ],\n",
       "        [-3.120862  ,  4.965311  ,  4.443643  ],\n",
       "        [-2.8576372 ,  5.409734  ,  5.0677414 ]],\n",
       "\n",
       "       [[ 0.9829832 ,  0.08484954,  0.34510058],\n",
       "        [ 0.9860618 ,  0.06193274,  0.31848025],\n",
       "        [ 1.0183877 ,  0.04310821,  0.32143807],\n",
       "        ...,\n",
       "        [ 6.3875594 ,  3.4699895 ,  8.507678  ],\n",
       "        [ 7.0002117 ,  3.2440953 ,  9.639534  ],\n",
       "        [ 7.515886  ,  2.9838257 , 10.531808  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.3277924 ,  0.31729147, -0.5708354 ],\n",
       "        [ 1.2862306 ,  0.34839284, -0.5826667 ],\n",
       "        [ 1.1461518 ,  0.40977713, -0.61914635],\n",
       "        ...,\n",
       "        [ 1.1307585 ,  0.39831874, -0.7137964 ],\n",
       "        [ 1.1107472 ,  0.41714326, -0.7394308 ],\n",
       "        [ 1.0630281 ,  0.42696476, -0.7640792 ]],\n",
       "\n",
       "       [[ 0.9429607 ,  0.5243612 , -0.72266984],\n",
       "        [ 0.9999157 ,  0.4891675 , -0.72266984],\n",
       "        [ 1.0522529 ,  0.45806614, -0.7177401 ],\n",
       "        ...,\n",
       "        [ 1.0507135 ,  0.4376047 , -0.735487  ],\n",
       "        [ 1.1153653 ,  0.41141406, -0.7492901 ],\n",
       "        [ 1.1369158 ,  0.39668182, -0.7502761 ]],\n",
       "\n",
       "       [[ 1.0307022 ,  0.44251543, -0.7719667 ],\n",
       "        [ 0.99375844,  0.45561075, -0.7798542 ],\n",
       "        [ 0.94142133,  0.48834905, -0.79957294],\n",
       "        ...,\n",
       "        [ 0.91987073,  0.5047182 , -0.8064745 ],\n",
       "        [ 0.8952415 ,  0.51535815, -0.830137  ],\n",
       "        [ 0.869073  ,  0.52927196, -0.84394014]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Models: 40320\n",
      "NEW MODEL: 1\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.1,\n",
      " 'drop2': 0.1,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00015: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36758    11]\n",
      " [   30     1]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.08      0.03      0.05        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.54      0.52      0.52     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 2\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.1,\n",
      " 'drop2': 0.2,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_32 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00032: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36769     0]\n",
      " [   31     0]]\n",
      "CLASSIFICATION REPORT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvganesh/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.50      0.50      0.50     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 3\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.1,\n",
      " 'drop2': 0.3,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_34 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00019: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36769     0]\n",
      " [   31     0]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.50      0.50      0.50     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 4\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.1,\n",
      " 'drop2': 0.4,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_36 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00011: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36768     1]\n",
      " [   27     4]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.80      0.13      0.22        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.90      0.56      0.61     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 5\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.2,\n",
      " 'drop2': 0.1,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_38 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00021: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36605   164]\n",
      " [   14    17]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.09      0.55      0.16        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.55      0.77      0.58     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 6\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.2,\n",
      " 'drop2': 0.2,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_40 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00029: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36755    14]\n",
      " [   11    20]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.59      0.65      0.62        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.79      0.82      0.81     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 7\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.2,\n",
      " 'drop2': 0.3,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_42 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00016: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[10752 26017]\n",
      " [   13    18]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.29      0.45     36769\n",
      "        fall       0.00      0.58      0.00        31\n",
      "\n",
      "    accuracy                           0.29     36800\n",
      "   macro avg       0.50      0.44      0.23     36800\n",
      "weighted avg       1.00      0.29      0.45     36800\n",
      "\n",
      "NEW MODEL: 8\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.2,\n",
      " 'drop2': 0.4,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_44 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00016: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36769     0]\n",
      " [   31     0]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.50      0.50      0.50     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 9\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.3,\n",
      " 'drop2': 0.1,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_46 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00036: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[29159  7610]\n",
      " [    7    24]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.79      0.88     36769\n",
      "        fall       0.00      0.77      0.01        31\n",
      "\n",
      "    accuracy                           0.79     36800\n",
      "   macro avg       0.50      0.78      0.45     36800\n",
      "weighted avg       1.00      0.79      0.88     36800\n",
      "\n",
      "NEW MODEL: 10\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.3,\n",
      " 'drop2': 0.2,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_48 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00026: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36764     5]\n",
      " [   21    10]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.67      0.32      0.43        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.83      0.66      0.72     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 11\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.3,\n",
      " 'drop2': 0.3,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_50 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 3)                 12        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00032: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[35499  1270]\n",
      " [   10    21]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.97      0.98     36769\n",
      "        fall       0.02      0.68      0.03        31\n",
      "\n",
      "    accuracy                           0.97     36800\n",
      "   macro avg       0.51      0.82      0.51     36800\n",
      "weighted avg       1.00      0.97      0.98     36800\n",
      "\n",
      "NEW MODEL: 12\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.3,\n",
      " 'drop2': 0.4,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00026: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36763     6]\n",
      " [    7    24]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.80      0.77      0.79        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.90      0.89      0.89     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 13\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.4,\n",
      " 'drop2': 0.1,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00034: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[33500  3269]\n",
      " [    5    26]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.91      0.95     36769\n",
      "        fall       0.01      0.84      0.02        31\n",
      "\n",
      "    accuracy                           0.91     36800\n",
      "   macro avg       0.50      0.87      0.48     36800\n",
      "weighted avg       1.00      0.91      0.95     36800\n",
      "\n",
      "NEW MODEL: 14\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.4,\n",
      " 'drop2': 0.2,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_56 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00013: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36769     0]\n",
      " [   31     0]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.50      0.50      0.50     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 15\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.4,\n",
      " 'drop2': 0.3,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_58 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00018: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36768     1]\n",
      " [   21    10]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.91      0.32      0.48        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.95      0.66      0.74     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEW MODEL: 16\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.4,\n",
      " 'drop2': 0.4,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.01,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_60 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_61 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00020: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36748    21]\n",
      " [    9    22]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.51      0.71      0.59        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.76      0.85      0.80     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 17\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.1,\n",
      " 'drop2': 0.1,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_62 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00031: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[12926 23843]\n",
      " [   12    19]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.35      0.52     36769\n",
      "        fall       0.00      0.61      0.00        31\n",
      "\n",
      "    accuracy                           0.35     36800\n",
      "   macro avg       0.50      0.48      0.26     36800\n",
      "weighted avg       1.00      0.35      0.52     36800\n",
      "\n",
      "NEW MODEL: 18\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.1,\n",
      " 'drop2': 0.2,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_64 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00027: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36447   322]\n",
      " [   19    12]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.99      1.00     36769\n",
      "        fall       0.04      0.39      0.07        31\n",
      "\n",
      "    accuracy                           0.99     36800\n",
      "   macro avg       0.52      0.69      0.53     36800\n",
      "weighted avg       1.00      0.99      0.99     36800\n",
      "\n",
      "NEW MODEL: 19\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.1,\n",
      " 'drop2': 0.3,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_66 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00034: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[32066  4703]\n",
      " [   13    18]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.87      0.93     36769\n",
      "        fall       0.00      0.58      0.01        31\n",
      "\n",
      "    accuracy                           0.87     36800\n",
      "   macro avg       0.50      0.73      0.47     36800\n",
      "weighted avg       1.00      0.87      0.93     36800\n",
      "\n",
      "NEW MODEL: 20\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.1,\n",
      " 'drop2': 0.4,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_68 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00028: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36730    39]\n",
      " [   11    20]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.34      0.65      0.44        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.67      0.82      0.72     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 21\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.2,\n",
      " 'drop2': 0.1,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_70 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_71 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00027: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36658   111]\n",
      " [   24     7]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.06      0.23      0.09        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.53      0.61      0.55     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 22\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.2,\n",
      " 'drop2': 0.2,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_72 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_73 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "CONFUSION MATRIX\n",
      "[[32069  4700]\n",
      " [    8    23]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.87      0.93     36769\n",
      "        fall       0.00      0.74      0.01        31\n",
      "\n",
      "    accuracy                           0.87     36800\n",
      "   macro avg       0.50      0.81      0.47     36800\n",
      "weighted avg       1.00      0.87      0.93     36800\n",
      "\n",
      "NEW MODEL: 23\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.2,\n",
      " 'drop2': 0.3,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_74 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_75 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "CONFUSION MATRIX\n",
      "[[36757    12]\n",
      " [    8    23]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.66      0.74      0.70        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.83      0.87      0.85     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 24\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.2,\n",
      " 'drop2': 0.4,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_76 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_77 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "CONFUSION MATRIX\n",
      "[[34612  2157]\n",
      " [    9    22]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      0.94      0.97     36769\n",
      "        fall       0.01      0.71      0.02        31\n",
      "\n",
      "    accuracy                           0.94     36800\n",
      "   macro avg       0.50      0.83      0.49     36800\n",
      "weighted avg       1.00      0.94      0.97     36800\n",
      "\n",
      "NEW MODEL: 25\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.3,\n",
      " 'drop2': 0.1,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_78 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_79 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "CONFUSION MATRIX\n",
      "[[36728    41]\n",
      " [    7    24]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.37      0.77      0.50        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.68      0.89      0.75     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 26\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.3,\n",
      " 'drop2': 0.2,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_80 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_81 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00041: early stopping\n",
      "CONFUSION MATRIX\n",
      "[[36765     4]\n",
      " [   23     8]]\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_fall       1.00      1.00      1.00     36769\n",
      "        fall       0.67      0.26      0.37        31\n",
      "\n",
      "    accuracy                           1.00     36800\n",
      "   macro avg       0.83      0.63      0.69     36800\n",
      "weighted avg       1.00      1.00      1.00     36800\n",
      "\n",
      "NEW MODEL: 27\n",
      "PARAMS: \n",
      "{'HL_1': 5,\n",
      " 'HL_2': 3,\n",
      " 'batch': 5000,\n",
      " 'drop1': 0.3,\n",
      " 'drop2': 0.3,\n",
      " 'epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'patience': 5,\n",
      " 'w0': 1.0,\n",
      " 'w1': 500.0}\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_82 (LSTM)               (None, 50, 5)             180       \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 50, 5)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 50, 5)             20        \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, 3)                 108       \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 308\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "### RUN GRID SEARCH OVERNIGHT\n",
    "\n",
    "bs = [5000, 7500, 10000, 15000, 20000]\n",
    "HL_1 = [5, 10, 15, 20, 25, 30, 35]\n",
    "dr1 = [0.1, 0.2, 0.3, 0.4]\n",
    "dr2 = [0.1, 0.2, 0.3, 0.4]\n",
    "HL_2 = [3, 5, 10, 15, 20, 25]\n",
    "weights = [500., 600., 700., 800.]\n",
    "lr = [0.01, 0.001, 0.0001]\n",
    "\n",
    "print(\"Number of Models:\", len(bs) * len(HL_1) * len(dr1) * len(dr2) * len(HL_2) * len(weights) * len(lr))\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "count = 1\n",
    "\n",
    "for b in bs:\n",
    "    for h1 in HL_1:\n",
    "        for h2 in HL_2:\n",
    "            for w in weights:\n",
    "                for l in lr:\n",
    "                    for d1 in dr1:\n",
    "                        for d2 in dr2:\n",
    "                            p = { # With Feature Scaling\n",
    "                                'drop1' : d1,\n",
    "                                'drop2': d2,\n",
    "                                'w1' : w,\n",
    "                                'w0' : 1.,\n",
    "                                'batch' : b,\n",
    "                                'epochs' : 50,\n",
    "                                'patience' : 5,\n",
    "                                'HL_1' : h1,\n",
    "                                'HL_2' : h2,\n",
    "                                'lr': l\n",
    "                            }\n",
    "                            print(\"NEW MODEL:\", count)\n",
    "                            print(\"PARAMS: \")\n",
    "                            pprint(p)\n",
    "                            history, cm, model = eval_lstm_cplx(X_train, Y_train, X_test, Y_test, 50, 3, p)\n",
    "                            count += 1\n",
    "                    \n",
    "\n",
    "print(\"TRAINING DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drop1': 0.4,\n",
       " 'drop2': 0.3,\n",
       " 'w1': 750.0,\n",
       " 'w0': 1.0,\n",
       " 'batch': 7500,\n",
       " 'epochs': 5,\n",
       " 'patience': 5,\n",
       " 'HL_1': 100,\n",
       " 'HL_2': 50}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer sequential_49: expected shape=(None, None, 3), found shape=[None, 50, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-3a8093e3344f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS2_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 2774\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[1;32m   2705\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 2706\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /Users/arvganesh/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer sequential_49: expected shape=(None, None, 3), found shape=[None, 50, 1]\n"
     ]
    }
   ],
   "source": [
    "pred_y = model.predict(S2_x)\n",
    "pred_y = np.round(pred_y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13, 14, 15, 18, 19]), array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pred_y[:30] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(S2_y, color=\"blue\")\n",
    "# plt.plot(pred_y, color\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
