{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4izO2n_XtmAW"
   },
   "source": [
    "# Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2wimTMRtmAY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, roc_curve, auc, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lstm_simple(X_train, Y_train, X_test, Y_test, time_steps, n_features, params):\n",
    "  # Build the Model\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(params['HL_1'], activation=tf.nn.relu, input_shape=(time_steps, n_features)))\n",
    "  model.add(Dropout(params['drop1']))\n",
    "  model.add(BatchNormalization())\n",
    "#   model.add(Dense(10, activation = tf.nn.relu))\n",
    "  model.add(Dense(1, activation = tf.nn.sigmoid))\n",
    "    \n",
    "#   opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "  callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = params['patience'], verbose=1)\n",
    "  model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = 'nadam', metrics=['accuracy'])\n",
    "\n",
    "  # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)\n",
    "  \n",
    "  # Implement class weights\n",
    "  cw = {\n",
    "      0: params['w0'],\n",
    "      1: params['w1']\n",
    "  }\n",
    "#   model.summary()\n",
    "    \n",
    "  # Train the model\n",
    "  history = model.fit(X_train, Y_train, epochs = params['epochs'], batch_size = params['batch'], class_weight=cw, callbacks=[callback])\n",
    "\n",
    "  # Predict on data\n",
    "  Y_pred = model.predict(X_test)\n",
    "  Y_pred = np.round(Y_pred, 0)\n",
    "  np.where(Y_pred == 1)\n",
    "  cm = confusion_matrix(Y_test, Y_pred)\n",
    "  print(\"CONFUSION MATRIX\")\n",
    "  print(cm)\n",
    "  print(\"CLASSIFICATION REPORT\")\n",
    "  print(classification_report(Y_test, Y_pred, target_names=[\"non_fall\", \"fall\"]))\n",
    "    \n",
    "  return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGhYLjlwtmBJ"
   },
   "source": [
    "## ROC for subject wise CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlbrXFbgtmBL"
   },
   "outputs": [],
   "source": [
    "def roc_outer_cross_val(X, Y, params, lb, feature_count):\n",
    "    subjects = [\"S1\", \"S2\", \"S3\", \"C1\", \"C2\", \"C3\"]\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    fold = 0\n",
    "    groups = [1,2,3,4,5,6]\n",
    "    split_model = LeaveOneGroupOut()\n",
    "    for train_index, test_index in split_model.split(X, Y, groups):\n",
    "        \n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "\n",
    "        for i in train_index:\n",
    "            X_train.append(X[i])\n",
    "            Y_train.append(Y[i])\n",
    "#             print(\"appending index: \",i,\"length of X_train after appending : \",len(X_train))\n",
    "        \n",
    "        X_train = np.vstack(X_train)\n",
    "        Y_train = np.vstack(Y_train)\n",
    "        print(\"Test Subject: \", subjects[test_index[0]])\n",
    "        X_test = X[test_index[0]]\n",
    "        Y_test = Y[test_index[0]]\n",
    "        \n",
    "        print(\"Final X_train: \",X_train.shape)\n",
    "        print(\"Final Y_train: \",Y_train.shape)\n",
    "        \n",
    "        history, model = eval_lstm_simple(X_train, Y_train, X_test, Y_test, lb, feature_count, params)        \n",
    "        probas = model.predict(X_test)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(Y_test, probas)\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        \n",
    "        fold += 1\n",
    "    \n",
    "    return tprs,mean_fpr,aucs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wnbw0HLutmCJ"
   },
   "source": [
    "## ROC graph on moving window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'mag' : ['accel_base_mag','fall_value'],\n",
    "    'XYZ' : ['accel_base_X','accel_base_Y','accel_base_Z','fall_value'],\n",
    "    'XYZ_mag' : ['accel_base_X','accel_base_Y','accel_base_Z','accel_base_mag','fall_value']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lb = 50\n",
    "rem_range = 500\n",
    "skip_val = 25\n",
    "feat_type = \"mag\"\n",
    "fall_buffer = 75\n",
    "feature_count = len(features[feat_type])-1\n",
    "\n",
    "# subjects = [S1, S2, S3, C1, C2, C3]\n",
    "subject_names = [\"S1\", \"S2\", \"S3\", \"C1\", \"C2\", \"C3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { # With Feature Scaling\n",
    "    'drop1' : 0.2,\n",
    "    'drop2': 0.2,\n",
    "    'w1' : 750.,\n",
    "    'w0' : 1.,\n",
    "    'batch' : 7500,\n",
    "    'epochs' : 2,\n",
    "    'patience' : 5,\n",
    "    'HL_1' : 15,\n",
    "    'HL_2' : 5,\n",
    "    'lr': 0.001,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting all TPR and FPR information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UtyKY0EtmCJ",
    "outputId": "35f57d63-485d-4685-b082-93b5e6ac8662",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lead_times = [10,100,200,300,400,2000]\n",
    "lead_times = [100]\n",
    "\n",
    "auc_values = []\n",
    "dict_tpr = dict()\n",
    "dict_fpr = dict()\n",
    "dict_auc = dict()\n",
    "\n",
    "for lead_time in lead_times:\n",
    "    X = []\n",
    "    Y = []\n",
    "    print(\"predicting on features for lead time:{} ms\".format(lead_time))\n",
    "    for sub in subject_names:\n",
    "        temp_path = \"../../../Features/Lead_Times/\"+str(lead_time)+\"ms/mag/\"\n",
    "        meta = \"_\" + str(feat_type) + \"_\" + str(lead_time) + \"ms_\" + str(lb) + \"lb\"\n",
    "        temp_sub_X = \"X_\" + sub + meta + \".npy\"\n",
    "        temp_sub_Y = \"Y_\" + sub + meta + \".npy\"\n",
    "        \n",
    "        temp_X = np.load(temp_path+ temp_sub_X).astype(np.float32)\n",
    "        temp_Y = np.load(temp_path+ temp_sub_Y).astype(np.float32)\n",
    "        \n",
    "        X.append(temp_X)\n",
    "        Y.append(temp_Y)\n",
    "    \n",
    "    tprs,mean_fpr,aucs = roc_outer_cross_val(X, Y, params,lb,feature_count)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    auc_values.append(round(mean_auc,3))\n",
    "    std_auc = np.std(aucs)\n",
    "    dict_tpr[lead_time] = mean_tpr\n",
    "    dict_fpr[lead_time] = mean_fpr\n",
    "    dict_auc[lead_time] = aucs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting ROC curve and Calculating sensitivity with fixed specificity (0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yp3X3t6ctmCM",
    "outputId": "050c2ae2-5800-4c26-9a79-c9f70b3224c9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yp3X3t6ctmCM",
    "outputId": "050c2ae2-5800-4c26-9a79-c9f70b3224c9"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3b0efdfba71c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlead_time\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlead_times\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmean_tpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_tpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlead_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmean_fpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_fpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlead_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_fpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_tpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 100"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lead_times = [10, 100, 200, 300, 400, 2000]\n",
    "lead_times = [100]\n",
    "auc_values = []\n",
    "\n",
    "specificity = 0.99\n",
    "tpr_tnr_table = pd.DataFrame(columns={'lead time(in ms)','sensitivity','specificity'})\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "for lead_time in lead_times:\n",
    "    mean_tpr = dict_tpr[lead_time]\n",
    "    mean_fpr = dict_fpr[lead_time]\n",
    "    sensitivity = np.interp(1-specificity,mean_fpr,mean_tpr)\n",
    "    tpr_tnr_table = tpr_tnr_table.append({'lead time(in ms)':lead_time,'sensitivity':round(sensitivity,3),'specificity':(specificity)},\n",
    "                       ignore_index = True)\n",
    "\n",
    "    aucs = dict_auc[lead_time] \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    auc_values.append(round(mean_auc,3))\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr,\n",
    "             label=str(lead_time)+' ms ROC (AUC = %0.2f )' % (mean_auc),\n",
    "             lw=2, alpha=.9)\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "     label='Chance', alpha=.8) \n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "plt.tick_params(labelsize=11)\n",
    "plt.xlabel('False Positive Rate',fontsize = 14 )\n",
    "plt.ylabel('True Positive Rate', fontsize = 14 )\n",
    "plt.legend(loc=\"lower right\")\n",
    "# img_name = 'ROC_curve'+' ms.png'\n",
    "# plt.savefig(img_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlSsmgr6tmBQ"
   },
   "source": [
    "## Sensitivity with Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>lead time(in ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [specificity, sensitivity, lead time(in ms)]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr_tnr_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tpr_tnr_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b1e68dd39d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# converting decimal to percentage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtpr_tnr_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensitivity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpr_tnr_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensitivity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" %\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#converting float to int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtpr_tnr_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lead time(in ms)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpr_tnr_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lead time(in ms)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tpr_tnr_table' is not defined"
     ]
    }
   ],
   "source": [
    "# converting decimal to percentage \n",
    "tpr_tnr_table['sensitivity'] = tpr_tnr_table['sensitivity'].apply(lambda x : str(round(x*100,1))+\" %\") \n",
    "#converting float to int\n",
    "tpr_tnr_table['lead time(in ms)'] = tpr_tnr_table['lead time(in ms)'].apply(lambda x : int(x)) \n",
    "\n",
    "tpr_tnr_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "E4pOx9MhtmA7",
    "orYEPNhItmBA",
    "iMeFzCCPtmBF",
    "fGhYLjlwtmBJ",
    "341kNOAoQWoV",
    "GE7LBnAEtmBU",
    "c6plf75CtmBV",
    "H6YGAlxGtmBZ",
    "2SOJryBptmBf",
    "RT0fVJeNtmBj",
    "uksNNXettmBp",
    "IDYkKyDRtmBt",
    "_UKufdhHtmCC",
    "st8qho5KjFrf",
    "GoM6U7uhtmB3",
    "Wnbw0HLutmCJ"
   ],
   "name": "moving window.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
